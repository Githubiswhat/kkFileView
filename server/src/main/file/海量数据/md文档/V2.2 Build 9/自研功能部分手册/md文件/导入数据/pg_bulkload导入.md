#### pg_bulkload导入

**功能描述**

可以使用pg_bulkload命令进行数据导入操作，提供高速数据加载能力。

**语法格式**

```
pg_bulkload [ OPTIONS ] [ controlfile ]
```

**参数说明**

pg_pulkload参数详情可参考<a href="https://ossc-db.github.io/pg_bulkload/pg_bulkload.html">pg_bulkload</a>

**注意事项**

- 执行此命令的用户需被赋予导出文件目录的读写权限。
- -i 参数支持通配符，暂时不支持使用正则表达式。

- 支持客户端使用加载工具，非数据库端。
- 支持导入错误的数据放到一个文件。
- 源数据文件需要支持可以使用纯文本格式的文件，字符集支持gbk、utf-8。
- 跳过数据库shared buffer ，快速写文件到数据库。
- 支持并发导入功能。
- 支持导入前设置是否对目标表truncate的参数。
- 在鲲鹏64核256GB服务器、存储选用SSD或NVME类型，网络无瓶颈的配置下，使用接口调用bulkload或工具远程使用bulkload功能可达到100M/s导入速度。
- 支持使用控制文件，可以把要使用的参数放入控制文件中。
- 支持指定单/双字节分隔符，例如特殊分隔符'∈'、'<|>'、'$|$'、'|'、'∈∈'。
- 支持为每个日期、时间字段指定格式。
- 选择源文件支持通配符导入多个文件至一个目标表。
- 支持跳过错误数据继续入库，达到阈值提交已入库数据。错误数据输出到文件，并生成导入报告，报告中显示导入成功与失败的记录数。
- 支持向一级分区表导入数据。

**性能指标**

Vastbase G100 V2.2版本对pg_bulkload功能相关性能做了大幅提升。

以鲲鹏64核256GB服务器，4*600G，RAID 5服务器配置为例，在网络无瓶颈的配置下，不同场景中可以达到相应的性能指标如下表：

| 场景                              | 性能指标                                                     |
| --------------------------------- | ------------------------------------------------------------ |
| 无索引表入库                      | 使用装载工具bulkload和Java API方式，在不论多文件同时导入还是单个文件导入的情况下，向无任何索引的单表(包括分区表)，入库速度达到100M/s以上。 |
| 有索引入库                        | 有索引下入库性能 > 5W(万行)/s，支持分区表且索引为全局索引的情况下也要保持这个入库速度。 |
| 创建索引性能提升                  | 针对已经创建好，并且已有入库数据的表，创建索引的速度能处理数据的速度达到30MB/s，这个速度是指索引体积的大小/创建索引的消耗时间。例如索引体积大小为300M，10秒内可以完成索引创建，即可满足要求。 |
| 全表扫描                          | 执行全表扫描时，顺序读、物理读的IO性能 > 400MB/s，允许使用并行技术。 |
| bulkload入库数据的I/O有写放大现象 | bulkload和Java API做大量数据导入时，真正在操作系统上产生的写入IO的量与导入的数据表的体积大小的比例，不能超过1.5倍，期望能控制在1.3倍以内。操作系统中IO写入总量可以用iostat等方法获取写入的总数量的估值。 |
| 入库完成后读表                    | 在bulkload导入了大量数据之后，已得到提示“导入成功”的前提下，做目标表的查询操作，数据库进程在操作系统层面给不能有大量写IO的表现。 |

**示例**

1、创建测试表。

```
drop table if exists blk_test;
create table blk_test(id int,col text);
```

2、创建导入文件。

```
vi bulkload.txt
1,张三
2,李四
```

3、导入数据。

```
pg_bulkload -i bulkload.txt -O blk_test -l output.log -o "TYPE=CSV" -o "DELIMITER=," -o "ENCODING=UTF8" -d vastbase
```

4、验证结果。

```
SELECT * FROM blk_test
```

当结果显示如下信息，则表示数据库导入完成。

```
id | col
----+------
1 | 张三
2 | 李四
(2 rows)
```

